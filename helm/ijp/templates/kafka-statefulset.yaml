apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  labels:
    app: kafka
spec:
  serviceName: kafka-headless # MUST match the headless service name
  replicas: {{ .Values.kafka.replicas }}
  selector:
    matchLabels:
      app: kafka
  persistentVolumeClaimRetentionPolicy:
    whenDeleted: Delete
    whenScaled: Retain
  template:
    metadata:
      labels:
        app: kafka
    spec:
      enableServiceLinks: false
      # Consider adding terminationGracePeriodSeconds for graceful shutdown
      # terminationGracePeriodSeconds: 60
      containers:
      - name: kafka
        image: {{ .Values.kafka.image.repository }}:{{ .Values.kafka.image.tag }}
        imagePullPolicy: {{ .Values.kafka.image.pullPolicy }}
        # Use command to set IDs and FQDNs correctly before Kafka starts
        command: ["/bin/bash", "-c"]
        args:
          - |
            # Set Strict Mode
            set -e
            set -u
            set -o pipefail

            # --- Configuration ---
            # If using Helm and deploying to a non-default namespace, replace 'default' with '{{ .Release.Namespace }}'
            NAMESPACE="default"
            HEADLESS_SERVICE_NAME="kafka-headless"
            CONTROLLER_PORT="9093"
            PLAINTEXT_PORT="9092"
            # Assumes KAFKA_REPLICAS env var is set below
            REPLICAS=${KAFKA_REPLICAS:-1} # Default to 1 if not set
            # Verify this path for your specific Kafka image version
            KAFKA_ENTRYPOINT="/etc/confluent/docker/run"
            # --- End Configuration ---

            echo "Starting Kafka configuration script..."

            # Extract the ordinal index from the hostname (e.g., kafka-0 -> 0)
            if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
              ORDINAL="${BASH_REMATCH[2]}"
            else
              echo "ERROR: Could not extract ordinal from hostname $HOSTNAME"
              exit 1
            fi
            export KAFKA_BROKER_ID=$ORDINAL
            export KAFKA_NODE_ID=$ORDINAL
            echo "Derived KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}"
            echo "Derived KAFKA_NODE_ID: ${KAFKA_NODE_ID}"

            # Construct the correct FQDN for this pod
            FQDN="${HOSTNAME}.${HEADLESS_SERVICE_NAME}.${NAMESPACE}.svc.cluster.local"
            export KAFKA_ADVERTISED_LISTENERS="PLAINTEXT://${FQDN}:${PLAINTEXT_PORT}"
            echo "Setting KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS}"

            # Construct voter string
            QUORUM_VOTERS=""
            if [[ $REPLICAS -lt 1 ]]; then
              echo "Warning: KAFKA_REPLICAS is less than 1, setting empty quorum voters."
            else
              for i in $(seq 0 $(($REPLICAS - 1))); do
                VOTER_FQDN="kafka-${i}.${HEADLESS_SERVICE_NAME}.${NAMESPACE}.svc.cluster.local"
                QUORUM_VOTERS="${QUORUM_VOTERS}${i}@${VOTER_FQDN}:${CONTROLLER_PORT},"
              done
              # Remove trailing comma
              QUORUM_VOTERS=${QUORUM_VOTERS%,}
            fi
            export KAFKA_CONTROLLER_QUORUM_VOTERS="${QUORUM_VOTERS}"
            echo "Setting KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS}"

            echo "--- Kafka Environment Variables Set By Script ---"
            echo "KAFKA_BROKER_ID=${KAFKA_BROKER_ID}"
            echo "KAFKA_NODE_ID=${KAFKA_NODE_ID}"
            echo "KAFKA_CONTROLLER_QUORUM_VOTERS=${KAFKA_CONTROLLER_QUORUM_VOTERS}"
            echo "KAFKA_ADVERTISED_LISTENERS=${KAFKA_ADVERTISED_LISTENERS}"
            echo "-------------------------------------------------"

            # Execute the original Kafka entrypoint/command
            echo "Executing Kafka entrypoint: ${KAFKA_ENTRYPOINT}..."
            exec ${KAFKA_ENTRYPOINT}

        ports:
        - name: plaintext
          containerPort: 9092
        - name: controller
          containerPort: 9093
        env:
        # --- KAFKA_BROKER_ID, KAFKA_NODE_ID, KAFKA_ADVERTISED_LISTENERS, KAFKA_CONTROLLER_QUORUM_VOTERS are now set by the command script ---
        # Pass replicas count needed by the command script
        - name: KAFKA_REPLICAS
          value: "{{ .Values.kafka.replicas }}"
        # --- Keep the rest of your static KAFKA_ variables ---
        - name: KAFKA_LISTENERS # Listen on all interfaces inside the container
          value: "PLAINTEXT://:9092,CONTROLLER://:9093"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        - name: KAFKA_CONTROLLER_LISTENER_NAMES
          value: "CONTROLLER"
        - name: KAFKA_PROCESS_ROLES
          value: "broker,controller"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "{{ .Values.kafka.replicas }}"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "{{ .Values.kafka.replicas }}"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          # Ensure minISR is not greater than replicas, common setting is replicas/2 + 1 or replicas-1 (safer for small clusters)
          value: "{{ max 1 (min (int .Values.kafka.replicas) (sub (int .Values.kafka.replicas) 1)) }}"
        - name: CLUSTER_ID
          value: "{{ .Values.kafka.clusterId }}"
        # Optional: Add JVM Heap settings via Values
        # - name: KAFKA_HEAP_OPTS
        #   value: "{{ .Values.kafka.heapOpts | default "-Xms512m -Xmx512m" }}"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data # Default Kafka data directory
        resources:
          {{- toYaml .Values.kafka.resources | nindent 10 }}
  # Volume Claim Template for persistent storage
  volumeClaimTemplates:
  - metadata:
      name: kafka-data # Name used in volumeMounts
    spec:
      accessModes: [ "ReadWriteOnce" ] # Suitable for StatefulSet pods
      storageClassName: {{ .Values.kafka.persistence.storageClass }}
      resources:
        requests:
          storage: {{ .Values.kafka.persistence.size }}